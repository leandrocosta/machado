\chapter{Introdução}
\label{chapter:introducao}

Há muito já não é mais novidade o fato de que vivemos, hoje, na chamada \textbf{Era da Informação} (termo cunhado por Daniel Bell, professor emérito da Universidade de Harvard), que se define pelo rápido desenvolvimento da tecnologia de informação, característica marcante da \textbf{Sociedade Pós-Industrial}, onde nota-se que, mais importante que possuir a informação, é saber onde e como encontrá-la.
\par
Ao longo dos últimos anos, o desenvolvimento tecnológico fez com que o constante armazenamento de dados se tornasse uma atividade fácil e barata. A conseqüência deste fato foi a alimentação de enormes bases de dados, o que proporcionou a  necessidade de se pensar em novas soluções de gerência, manutenção e, posteriormente, acesso.
\par
Os Sistemas de Gerenciamento de Banco de Dados (\textbf{SGBD}) surgiram como uma solução para gerência e manutenção de bases, com o objetivo de retirar da aplicação cliente a responsabilidade de gerenciar o acesso, a manipulação e a organização dos dados. Entretanto, embora os complexos SGBD's tenham se consolidado como eficientes sistemas na gerência de complexos volumes de dados, e tratado com eficácia a recuperação de informações em grandes coleções, da existência de tais bases surgiu a necessidade de métodos mais avançados de recuperação de informação, como redução de volume de dados, extração da essência da informação armazenada, descoberta de padrões, dentre outros.
\par
Como resposta à necessidade dos novos métodos de recuperação de informação, surgiu o que chamamos hoje de \textbf{Mineração de Dados}.

\section{Mineração de Dados}

Mineração de dados é o resultado de um longo processo de pesquisa e desenvolvimento, considerado uma das mais importantes fronteiras entre bases de dados e sistemas de informação, e um dos mais promissores desenvolvimentos interdisciplinares na tecnologia da informação \citep{Han00}. Podemos defini-la como o conjunto de métodos não triviais de análise de dados e extração de informação potencialmente útil, implícita, previamente desconhecida, e suas novas formas de representação e visualização \citep{Kumar06, Hand01, PiatetskyF91}.
\par
O termo Mineração de Dados é freqüentemente mencionado no contexto de \textbf{Descoberta de Conhecimento em Bases de Dados} (\textbf{KDD - \textit{Knowledge Discovery in Databases}}), definido como um processo de extração de conhecimentos válidos, novos, potencialmente úteis e compreensíveis para apoiar a tomada de decisão \citep{Fayyad96}. Para tanto, o KDD faz uso de diversos artifícios, incluindo métodos estatísticos, reconhecimento de padrões, visualização, banco de dados, aprendizado de máquia, inteligência artificial, \textit{data warehouse}, dentre outros \citep{Sassi06}.
\par
O processo de descoberta de conhecimento em bases de dados consiste na seguinte seqüência de etapas:

\begin{enumerate}
	\item{Aprendizado:} Entendimento do domínio da aplicação, que inclui conhecimento prévio da aplicação e dos seus objetivos;
	\item{Seleção:} Coleta dos dados, constituído pela definição de uma base de dados e pela seleção de um conjunto (ou sub-conjunto) de dados e atributos a serem considerados;
	\item{Pré-processamento:} Abrange execução de operações básicas como remoção de ruídos, definição de procedimentos e estratégias aplicáveis a dados faltosos, decisões relacionadas a tipos de dados, dentre outras tarefas;
	\item{Transformação:} Consiste na definição de atributos indicados para representar os dados, definição da dimensionalidade dos dados, e outros métodos de transformação para reduzir o número de variáveis sob consideração;
	\item{Mineração de Dados:} Inclui a escolha da função de mineração de dados, de acordo com o propósito do modelo (podendo ser classificação, agrupamento, sumarização, etc.), e do algoritmo a ser aplicado, que depende de decisões como qual modelo é mais apropriado considerando-se a natureza dos dados. Por exemplo, modelos para dados categóricos são diferentes de modelos para dados contínuos. A execução da mineração de dados se resume em pesquisar por padrões de interesse numa representação (ou conjunto de representações) definida de acordo com a função de mineração de dados escolhida;
	\item{Interpretação e Avaliação:} Esta etapa pode resultar no retorno a qualquer um dos passos anteriores, caso os resultados não sejam satisfatórios, e alguma alteração seja necessária para a sua melhoria;
	\item{Utilização do Conhecimento:} Consiste na incorporação do conhecimento adquirido promovendo ações ou simplesmente documentando e reportando resultados para as partes de interesse.
\end{enumerate}

De acordo com \cite{Fayyad96}, mineração de dados é um passo do processo KDD que consiste na enumeração de padrões sobre os dados, sujeito a aceitáveis limitações de eficiência computacional. Considerando que padrões enumeráveis sobre uma base finita de dados são potencialmente infinitos, e que tal enumeração envolve alguma forma de pesquisa num espaço amplo, limitações computacionais adicionam severos limites sobre o sub-espaço que pode ser explorado por um algoritmo de mineração de dados. Por este motivo, a constante busca por novas metodologias e algoritmos de enumeração de padrões em grandes bases de dados têm sido foco de inúmeras frentes de pesquisa em mineração de dados.
\par
Nas próximas sub-seções apresentaremos definições e fundamentos teóricos necessários para entendimento do restante do documento.

%\par
%A princípio, mineração de dados é uma técnica que pode ser aplicada a quaisquer tipos de dados, incluindo dados de transações, \textit{multimedia}, dados espaciais, informações temporais, e até mesmo a \textbf{WWW} (\textit{World Wide Web}). Os tipos de padrões que podem se descobertos dependem das funcionalidades aplicadas. As funcionalidades de mineração de dados e a variedade de conhecimento que elas podem descobrir são apresentadas na seguinte lista:

%\begin{itemize}
%	\item{Caracterização:} Categorização de dados
%\end{itemize}
%
%Que tipo de dado pode ser minerado?
%\par
%O que pode ser descoberto?
%\par
%Tudo o que pode ser descoberto é de interesse do usuário?
%\par
%Como sistemas de mineração de dados podem ser categorizados?
%\par
%What are the "issues"?
%\par
%Falar das soluções encontradas na mineração de dados para resolver os problemas citados, (agrupamento, regras associativas, etc). "Mineração de dados é uma tecnologia usada para revelar informação estratégica escondida em grandes massas de dados". \\
%fonte: http://br.geocities.com/dugimenes/mineracao.htm \\
%fonte: http://pt.wikipedia.org/wiki/Minera\%C3\%A7\%C3\%A3o\_de\_dados \\
%Citar \cite{Kumar06}. \\
%Procurar livros, como \cite{Han00}. \\
%http://books.google.com/books?hl=en\&lr=\&id=AfL0t-YzOrEC\&oi=fnd\&pg=PR21\&dq=data+mining\&ots=UuSVuVarG6\&sig=swJzbDeqSGlffWudUjXszg5vNPA\#PPP1,M1

\subsection{Padrões Freqüentes}

De acordo com \cite{goethals03survey}, padrões freqüentes assumem um papel essencial em muitas tarefas de mineração de dados que têm, como objetivo, encontrar padrões de interesse numa base, tais como regras de associação, correlações, seqüências, episódios, classificadores, agrupamentos e muitos outros dos quais a mineração de regras de associação é um dos problemas mais populares. Desde a introdução deste termo, em 1993, por \citeauthor{agrawal93mining}, a mineração de padrões freqüentes e regras de associação têm recebido grande atenção. Nas últimas décadas, centenas de artigos científicos foram publicados apresentando novos algoritmos (ou melhorias para os anteriormente desenvolvidos) para resolver estes problemas de forma mais eficiente. O problema da mineração de padrões freqüentes pode ser descrito da seguinte forma:
\par
Seja $\mathcal{I}$ um conjunto de itens. Um conjunto $X = \left\{i_1, \cdots, i_k\right\} \subseteq \mathcal{I}$ é chamado de \textit{itemset}, ou \textit{k-itemset} se ele contém $k$ itens.
\par
Uma transação sobre $\mathcal{I}$ é um par $T = \left(tid, I\right)$ onde $tid$ é o identificador da transação e $I$ é um \textit{itemset}. Dizemos que uma transação $T = \left(tid, I\right)$ é coberta por um \textit{itemset} $X \subseteq \mathcal{I}$, se $X \subseteq I$.
\par
Uma base de dados de transações $\mathcal{D}$ sobre $\mathcal{I}$ é um conjunto de transações sobre $\mathcal{I}$. Omitiremos $\mathcal{I}$ sempre que a sua dedução for trivial, de acordo com o contexto.
\par
A cobertura de um \textit{itemset} $X$ em $\mathcal{D}$ consiste no conjunto de identificadores de transações das transações em $\mathcal{D}$ cobertas por $X$: \[cobertura(X,\mathcal{D}) := \left\{ tid |(tid,I) \in \mathcal{D}, X \subseteq I \right\}.\]

O suporte de um \textit{itemset} $X$ em $\mathcal{D}$ é o número de transações cobertas por $X$ em $\mathcal{D}$: \[suporte(X,\mathcal{D}) := |cobertura(X,\mathcal{D})|.\]

A freqüência de um \textit{itemset} $X$ em $\mathcal{D}$ é a probabilidade de $X$ ocorrer em uma transação $T \in \mathcal{D}$: \[frequencia(X,\mathcal{D}) := P(X) = \frac{suporte(X,\mathcal{D})}{|\mathcal{D}|}.\]

Note que $|\mathcal{D}| = suporte(\left\{\right\},\mathcal{D})$. Omitiremos $\mathcal{D}$ sempre que a sua dedução for trivial, de acordo com o contexto.
\par
Um \textit{itemset} é freqüente se o seu suporte é maior ou igual a um dado valor absoluto mínimo $\sigma_{abs}$, com $0 \leq \sigma_{abs} \leq |\mathcal{D}|$. Quando se considera freqüências de \textit{itemsets} ao invés de suportes, é utilizado um valor relativo $\sigma_{rel}$, com $0 \leq \sigma_{rel} \leq 1$. Obviamente, $\sigma_{abs} = \left\lceil \sigma_{rel} \cdot |\mathcal{D}| \right\rceil$. No restante deste texto, sempre que não especificarmos a natureza de $\sigma$, $\sigma_{rel}$ deve ser considerado.

\begin{definition}
Seja $\mathcal{D}$ uma base de dados de transações sobre um conjunto de itens $\mathcal{I}$, e $\sigma$ um valor mínimo de suporte. A coleção de \textit{itemsets} freqüentes em $\mathcal{D}$ em relação a $\sigma$ é dado por: \[\mathcal{F}(\mathcal{D},\sigma):=\left\{X \subseteq \mathcal{I} | suporte (X,\mathcal{D}) \geq \sigma \right\}.\]
\end{definition}

\begin{problem}[Mineração de Padrões Freqüentes]
Dado um conjunto de itens $\mathcal{I}$, uma base de dados de transações $\mathcal{D}$ sobre $\mathcal{I}$, e um suporte mínimo $\sigma$, encontre $\mathcal{F}(\mathcal{D},\sigma)$.
\end{problem}

Na prática, não estamos interessados apenas no conjunto de \textit{itemsets} $\mathcal{F}$, mas também nos respectivos suportes desses \textit{itemsets}. Na próxima seção apresentaremos definições e fundamentos teóricos relacionados à mineração de regras de associação.

%Ótimo Survey sobre mineração de padrões freqüentes (possui descrição do problema, mineração de itemsets, espaço de busca, regras de associação, algoritmo apriori fp-growth, etc...): \cite{goethals03survey}.

\subsection{Regras de Associação}

Em mineração de dados, regras de associação são utilizadas para descobrir elementos que co-ocorrem freqüentemente numa determinada base de dados. A motivação por trás deste tema está relacionada com a grande quantidade de aplicações possíveis de se construir com o auxílio de regras de associação, como por exemplo, questões relacionadas ao comportamento de clientes num determinado estabelecimento comercial.
\par
Considerando uma base de dados de transações em que cada transação represente uma ação de compra de determinado cliente, e cada item da transação represente um produto adquirido, regras de associação seriam uma boa escolha para responder questões como:

\begin{itemize}
	\item Encontre todas as regras que possuem ``café'' como conseqüente. Estas regras poderiam auxiliar o usuário a planejar o que deve ser feito no estabelecimento para aumentar a venda do produto;
	\item Encontre todas as regras que possuem ``café'' como antecedente. Com estas regras seria possível descobrir que produtos serão impactados se o estabelecimento optar por descontinuar a venda daquele produto;
	\item Encontre todas as regras que possuem ``café'' como antecedente e ``leite'' como conseqüente. Esta requisição poderia ser realizada para todos os produtos do estabelecimento, com a intenção de se encontrar produtos cujo consumo esteja relacionado;
	\item Encontre todas as regras relacionando itens localizados nas prateleiras A e B do estabelecimento. Estas regras poderiam auxiliar no planejamento das prateleiras, e na localização dos produtos;
	\item Encontre as $k$ ``melhores'' regras que possuem ``café'' como conseqüente. As ``melhores'' regras podem ser obtidas com o auxílio de métricas associadas a cada regra, como suporte e confiança.
\end{itemize}
	
\par
Uma regra de associação é uma aplicação da forma $X \Rightarrow Y$, onde $X$ é um conjunto de itens em $\mathcal{I}$, e $Y$ é um único item em $\mathcal{I}$ que não está presente em $X$. A regra $X \Rightarrow Y$ é satisfeita no conjunto de transações $T$ com confiança $0 \leq c \leq 1$ se, e somente se, pelo menos $c$\% das transações em $T$ que satisfazem $X$ também satisfazem $Y$ \citep{agrawal93mining}.
\par
O suporte de uma regra $X \Rightarrow Y$ em $\mathcal{D}$ é o suporte de $X \cup Y$ em $\mathcal{D}$, e a freqüência da regra é a freqüência de $X \cup Y$. Dizemos que uma regra de associação é freqüente se o seu suporte excede um determinado valor mínimo $\sigma_{abs}$ (ou $\sigma_{rel}$).
\par
A confiança de uma regra de associação $X \Rightarrow Y$ em $\mathcal{D}$ é a probabilidade condicional de encontrar $Y$ numa transação, dado que esta contém $X$: \[confianca(X \Rightarrow Y,\mathcal{D}):=P(Y|X) = \frac{suporte(X \cup Y,\mathcal{D})}{suporte(X,\mathcal{D})}.\]

Dizemos que a regra é de confiança se $P(X|Y)$ excede um determinado valor mínimo de confiança $\gamma$, com $0 \leq \gamma \leq 1$.

\begin{definition}
Seja $\mathcal{D}$ uma base de dados de transações sobre um conjunto de itens $\mathcal{I}$, $\sigma$ um valor mínimo para suporte e $\gamma$ um valor mínimo para confiança, o conjunto de regras de associação freqüentes e de confiança considerando $\sigma$ e $\gamma$ é dado por: \[\mathcal{R}(\mathcal{D},\sigma,\gamma):=\left\{X \Rightarrow Y|X,Y \subseteq \mathcal{I}, X \cap Y = \left\{ \right\}, X \cup Y \in \mathcal{F}(\mathcal{D},\sigma),confianca(X \Rightarrow Y,\mathcal{D}) \geq \gamma\right\}.\]
\end{definition}

\begin{problem}[Mineração de Regras de Associação]
Dado um conjunto de itens $\mathcal{I}$, uma base de dados de transações $\mathcal{D}$ sobre $\mathcal{I}$, um valor mínimo para suporte $\sigma$ e um valor mínimo para confiança $\gamma$, encontre $\mathcal{R}(\mathcal{D},\sigma,\gamma)$.
\end{problem}

Além do conjunto de regras de associação, estamos interessados também no suporte e na confiança de cada regra. Na próxima seção, apresentaremos definição e exemplos de utilização do termo ortogonalidade (também explorado pelo restante do documento) na ciência da computação.

%\par
%Artigo que fala de classificação e Regras de Associação: \cite{liu98integrating} (CBA)
%O Survey também fala de regras de associação: \cite{goethals03survey}.
%Artigo do Zaki, que fala também (CHARM): \cite{zaki99charm}.
%Novos algoritmos para descoberta rápida de regras de associação: \cite{DBLP:conf/kdd/ZakiPOL97}.

\section{Ortogonalidade}

Em matemática, ortogonalidade é simplesmente uma característica que denota perpendicularidade, ou existência de ângulos retos. Formalmente, dois vetores $x$ e $y$ são ortogonais num espaço vetorial $V$ se o produto interno $\left\langle x,y \right\rangle$ é zero. Esta situação é descrita por $x \bot y$.
\par
O termo pode ser estendido para o uso geral, denotando a característica de independência, não redundância, não sobreposição, e, até mesmo, irrelevância entre duas entidades. Neste trabalho, o termo ortogonalidade está mais relacionado com a ausência de redundância e sobreposição, ou seja, o inverso da similaridade.
\par
Os termos similaridade e ortogonalidade têm sido explorados em várias áreas da ciência da computação, e com diversos objetivos. Um exemplo é o caso do \textbf{Modelo de Espaço Vetorial}, aplicado à \textbf{Recuperação de Informação}, que utiliza modelos vetoriais e métricas de similaridade para se aproximar termos da pesquisa de um usuário aos documentos de determinada coleção.
\par
De acordo com \cite{salton75vsm}, o modelo de espaço vetorial, ou simplesmente modelo vetorial, representa documentos e consultas como vetores de termos. Aos termos das consultas e documentos são atribuídos pesos que especificam o tamanho e a direção de seu vetor de representação. Estes pesos são utilizados para calcular o grau de similaridade entre cada documento da coleção e a consulta de usuário. Dessa forma, o modelo vetorial leva em consideração documentos que casam com a consulta de forma parcial. Como resultado, o conjunto de respostas é ordenado de forma mais precisa que o antigo e limitado modelo booleano.
\par
Já a ortogonalidade, particularmente, tem sido explorada em áreas como visualização \citep{cui07}, reconhecimento facial \citep{nagao98}, taxonomia \citep{smith00}, dentre outras.
\par
Como exemplo de aplicação do termo em mineração de dados, podemos citar \cite{DBLP:conf/kdd/XinCYH06}, que utiliza métricas de significância e redundância para extrair, de um grande conjunto de padrões freqüentes, um sub-conjunto (top-$k$) de padrões com um valor mínimo de redundância. O autor comenta que este estudo abriu uma nova direção na procura por diferentes e significantes top-$k$ respostas para atividades de mineração de dados, que podem resultar em estudos promissores.
\par
Na próxima seção serão apresentados os objetivos deste trabalho, relacionados com os termos apresentados nesta introdução - mineração de dados, padrões freqüentes, regras de associação e ortogonalidade.

% como forma de se obter uma medida de dissimilaridade entre duas entidades quaisquer. Um exemplo é o caso do \textbf{Modelo de Espaço Vetorial}, aplicado à \textbf{Recuperação de Informação}.
%\par
%De acordo com \cite{salton75vsm}, o modelo de espaço vetorial, ou simplesmente modelo vetorial, representa documentos e consultas como vetores de termos. Termos são ocorrências únicas nos documentos. Os documentos devolvidos como resultado para uma consulta são representados similarmente, ou seja, o vetor resultado para uma consulta é montado através de um cálculo de similaridade. Aos termos das consultas e documentos são atribuídos pesos que especificam o tamanho e a direção de seu vetor de representação. Ao ângulo formado por estes vetores dá-se o nome de $q$. O termo $\cos(q)$ determina a proximidade da ocorrência. O cálculo da similaridade é baseado neste ângulo entre os vetores que representam o documento e a consulta.

%Boa fonte para ortogonalidade (termo geral) - wikepedia: http://en.wikipedia.org/wiki/Orthogonal \\
%Citar poucos artigos que tratam de ortogonalidade, como ORIGAMI \citep{zaki07origami}, Redundancy-Aware Top-k Patterns \citep{DBLP:conf/kdd/XinCYH06} e Orthogonal Decision Trees \citep{dutta2004orthogonal}. \\
%Procurar mais fontes.

\section{Objetivos}

Este trabalho visa explorar o problema de classificação associativa em mineração de dados considerando ortogonalidade entre padrões freqüentes com os seguintes objetivos:

\begin{itemize}
	\item Minimizar o número de padrões utilizados na geração das regras, extraindo, do conjunto de padrões freqüentes, um sub-conjunto de padrões ortogonais, para que, a partir destes, seja gerado o conjunto de regras associativas necessárias para se realizar a classificação;
	\item Diminuir a redundância das regras geradas, como conseqüência da utilização de ortogonalidade aplicada à estrutura dos padrões;
	\item Diminuir a ambigüidade das regras associativas, como conseqüência da utilização de ortogonalidade aplicada à cobertura de classes e transações;
	\item Aumentar a efetividade das classificações, como conseqüência da diminuição da redundância e da ambigüidade das regras, de acordo com os itens acima.
\end{itemize}

\section{Trabalhos Relacionados}

Na área de mineração de dados existem diversos trabalhos relacionados tanto com classificação quanto com ortogonalidade. Em \cite{DBLP:conf/kdd/XinCYH06}, os autores introduzem o problema da extração dos top-$k$ padrões livres de redundância através de um modelo que integra duas métricas - significância e redundância - numa única função objetivo. A idéia é obter, como resultado, um conjunto de $k$ padrões de alta significância e baixa redundância entre seus elementos. O artigo apresenta duas funções objetivo, e descreve um algoritmo guloso que resolve o problema com ordem de complexidade de tempo $O(\log k)$.
\par
Em \cite{Veloso06Lazy}, como já mencionado, é introduzida uma nova abordagem de classificação associativa - a abordagem \textit{lazy}. Este artigo discute a nova solução, e a compara com a abordagem \textit{eager} bastante explorada anteriormente, e apresenta a demonstração de que classificadores associativos baseados na abordagem \textit{lazy} produzem resultados iguais ou melhores que os baseados na abordagem \textit{eager}.
\par
Em \cite{veloso06multi}, os autores utilizam a abordagem \textit{lazy} de classificação associativa direcionado para classificação de documentos. O artigo apresenta um algoritmo de classificação capaz de analisar tanto o conteúdo dos documentos quanto a presença de \textit{links} de saída e de entrada para outros documentos. As inovações introduzidas pelos autores produzem resultados mais efetivos e de maior desempenho que abordagens do estado da arte nas coleções utilizadas.
\par
Em \cite{zaki07origami} encontramos um novo paradigma para obtenção de uma representação resumida do conjunto de padrões freqüentes. O artigo introduz uma abordagem randômica para obtenção de padrões maximais que possui, como principal característica, a possibilidade de cobrir uniformemente o espaço dos padrões, e apresenta a formulação da obtenção do conjunto $\alpha$-ortogonal e $\beta$-representativo como um problema de otimização NP-Hard. Esta abordagem será discutida com mais detalhes na seção \ref{sec:ortogonalidade_origami}.

%Falar de \cite{DBLP:conf/kdd/KnobbeH06}, que obtém, de um conjunto de itens, um itemset que particione uma base de dados o mais uniformemente possível.
%Falar de \cite{DBLP:conf/icde/LentSW97} ??? artigo que realiza agrupamento de regras de associação num espaço bi-dimensional.
%Falar de \cite{DBLP:conf/kdd/XinCYH06}, que extrai top-k padrões minimizando a redundância de um conjunto de padrões frequentes.
%Falar sobre o ORIGAMI \cite{zaki07origami}.
%Falar sobre o lazy \cite{Veloso06Lazy}

\section{Organização do Documento}

Este documento é dividido em cinco capítulos. O restante dos capítulos está organizado da seguinte forma:

\begin{itemize}
	\item O capítulo \ref{chapter:classificacao} possui uma base de informações relacionadas à classificação associativa, como definição do problema, definição e comparação entre as estratégias \textit{eager} e \textit{lazy}, e uma breve apresentação das métricas mais utilizadas para se comparar regras de associação;
	\item No capítulo \ref{chapter:ortogonalidade} será apresentada a nova estratégia de classificação baseada em ortogonalidade. O conteúdo inclui uma discussão sobre métricas e estratégias de ortogonalidade utilizadas, uma explicação detalhada da utilização de ortogonalidade e pelo classificador e das heurística de obtenção de conjuntos ortogonais, e ainda a adaptação da estratégia ORIGAMI (encontrada na literatura) para o problema de classificação;
	\item No capítulo \ref{chapter:resultados} serão apresentados os experimentos executados e os resultados obtidos durante a realização do trabalho;
	\item O capítulo \ref{chapter:conclusao} possui um breve resumo do que foi apresentado, além de sugestões para futuros trabalhos relacionados ao tema.
\end{itemize}