\chapter{Introdução}
\label{chapter:introducao}

Há muito já não é mais novidade o fato de que vivemos, hoje, na chamada \textbf{Era da Informação} (termo cunhado por Daniel Bell, professor emérito da Universidade de Harvard), que se define pelo rápido desenvolvimento da tecnologia de informação, característica marcante da \textbf{Sociedade Pós-Industrial}, onde nota-se que, mais importante que possuir a informação, é saber onde e como encontrá-la.
\par
Ao longo dos últimos anos, o desenvolvimento tecnológico fez com que o constante armazenamento de dados se tornasse uma atividade fácil e barata. A conseqüência deste fato foi a alimentação de enormes bases de dados, o que proporcionou a  necessidade de se pensar em novas soluções de gerência, manutenção e, posteriormente, acesso.
\par
Os Sistemas de Gerenciamento de Banco de Dados (\textbf{SGBD}) surgiram como uma solução para gerência e manutenção de bases, com o objetivo de retirar da aplicação cliente a responsabilidade de administrar o acesso, a manipulação e a organização dos dados. Entretanto, embora os complexos SGBD's tenham se consolidado como eficientes sistemas na gerência de grandes volumes de dados, e tratado com eficácia a recuperação de informações em amplas coleções, da existência de tais bases surgiu a necessidade de métodos mais avançados de recuperação de informação, como redução de volume de dados, extração da essência da informação armazenada, descoberta de padrões, dentre outros.
\par
Como resposta à necessidade dos novos métodos de recuperação de informação, surgiu o que chamamos hoje de \textbf{Mineração de Dados}.

\section{Mineração de Dados}

Mineração de dados é o resultado de um longo processo de pesquisa e desenvolvimento, considerado uma das mais importantes fronteiras entre bases de dados e sistemas de informação, e um dos mais promissores desenvolvimentos interdisciplinares na tecnologia da informação \citep{Han00}. Podemos defini-la como o conjunto de métodos não triviais de análise de dados e extração de informação potencialmente útil, implícita, previamente desconhecida, e suas novas formas de representação e visualização \citep{Kumar06, Hand01, PiatetskyF91}.
\par
O termo Mineração de Dados é mencionado com freqüência no contexto de \textbf{Descoberta de Conhecimento em Bases de Dados} (\textbf{KDD - \textit{Knowledge Discovery in Databases}}), definido como um processo de extração de conhecimentos válidos, novos, potencialmente úteis e compreensíveis para apoiar a tomada de decisão \citep{Fayyad96}. Para tanto, o KDD faz uso de diversos artifícios, incluindo métodos estatísticos, reconhecimento de padrões, visualização, banco de dados, aprendizado de máquina, inteligência artificial, \textit{data warehouse}, dentre outros \citep{Sassi06}.
\par
O processo de descoberta de conhecimento em bases de dados consiste na seguinte seqüência de etapas:

\begin{enumerate}
	\item{Aprendizado:} Entendimento do domínio da aplicação, que inclui conhecimento prévio da aplicação e dos seus objetivos;
	\item{Seleção:} Coleta dos dados, constituído pela definição de uma base de dados e pela seleção de um conjunto (ou sub-conjunto) de dados e atributos a serem considerados;
	\item{Pré-processamento:} Abrange a execução de operações básicas como remoção de ruídos, a definição de procedimentos e estratégias aplicáveis a dados faltosos, decisões relacionadas a tipos de dados, dentre outras tarefas;
	\item{Transformação:} Consiste na definição de atributos indicados para representar os dados, na definição da dimensionalidade dos dados, e em outros métodos de transformação para reduzir o número de variáveis sob consideração;
	\item{Mineração de Dados:} Inclui a escolha da função de mineração de dados, de acordo com o propósito do modelo (podendo ser classificação, agrupamento, sumarização, etc.), e do algoritmo a ser aplicado, que depende de decisões como qual modelo é mais apropriado considerando-se a natureza dos dados. Por exemplo, modelos para dados categóricos são diferentes de modelos para dados contínuos. A execução da mineração de dados se resume em pesquisar por padrões de interesse numa representação (ou conjunto de representações) definida de acordo com a função de mineração de dados escolhida;
	\item{Interpretação e Avaliação:} Esta etapa pode resultar no retorno a qualquer um dos passos anteriores, caso os resultados não sejam satisfatórios e alguma alteração seja necessária para a sua melhoria;
	\item{Utilização do Conhecimento:} Consiste na incorporação do conhecimento adquirido promovendo ações ou simplesmente documentando e reportando resultados para as partes de interesse.
\end{enumerate}

De acordo com \cite{Fayyad96}, mineração de dados é um passo do processo KDD que consiste na enumeração de padrões sobre os dados, sujeito a aceitáveis limitações de eficiência computacional. Considerando que padrões enumeráveis sobre uma base finita de dados são potencialmente infinitos, e que tal enumeração envolve alguma forma de pesquisa num espaço amplo, limitações computacionais adicionam severos limites sobre o sub-espaço que pode ser explorado por um algoritmo de mineração de dados. Por este motivo, a constante busca por novas metodologias e algoritmos de enumeração de padrões em grandes bases de dados têm sido foco de inúmeras frentes de pesquisa em mineração de dados.

%\par
%A princípio, mineração de dados é uma técnica que pode ser aplicada a quaisquer tipos de dados, incluindo dados de transações, \textit{multimedia}, dados espaciais, informações temporais, e até mesmo a \textbf{WWW} (\textit{World Wide Web}). Os tipos de padrões que podem se descobertos dependem das funcionalidades aplicadas. As funcionalidades de mineração de dados e a variedade de conhecimento que elas podem descobrir são apresentadas na seguinte lista:

%\begin{itemize}
%	\item{Caracterização:} Categorização de dados
%\end{itemize}
%
%Que tipo de dado pode ser minerado?
%\par
%O que pode ser descoberto?
%\par
%Tudo o que pode ser descoberto é de interesse do usuário?
%\par
%Como sistemas de mineração de dados podem ser categorizados?
%\par
%What are the "issues"?
%\par
%Falar das soluções encontradas na mineração de dados para resolver os problemas citados, (agrupamento, regras associativas, etc). "Mineração de dados é uma tecnologia usada para revelar informação estratégica escondida em grandes massas de dados". \\
%fonte: http://br.geocities.com/dugimenes/mineracao.htm \\
%fonte: http://pt.wikipedia.org/wiki/Minera\%C3\%A7\%C3\%A3o\_de\_dados \\
%Citar \cite{Kumar06}. \\
%Procurar livros, como \cite{Han00}. \\
%http://books.google.com/books?hl=en\&lr=\&id=AfL0t-YzOrEC\&oi=fnd\&pg=PR21\&dq=data+mining\&ots=UuSVuVarG6\&sig=swJzbDeqSGlffWudUjXszg5vNPA\#PPP1,M1

\subsection{Padrões Freqüentes}

De acordo com \cite{Han00}, são chamados padrões freqüentes aqueles que aparecem repetidamente num conjunto de dados. Por exemplo, um par de itens, como ``café'' e ``leite'', que aparecem juntos assiduamente em transações de uma base de dados, é considerado um padrão freqüente. Uma seqüência, como comprar uma câmera fotográfica, e logo depois um cartão de memória, se ocorre muitas vezes na base de dados de um estabelecimento comercial, também é considerada um padrão freqüente.
\par
Padrões freqüentes assumem um papel essencial em muitas tarefas de mineração de dados que possuem, como objetivo, encontrar padrões de determinado interesse numa base, tais como regras de associação, correlações, seqüências, episódios, classificadores, agrupamentos e muitas outras das quais a mineração de regras de associação é uma das mais populares \citep{goethals03survey}. Desde a introdução deste termo, em 1993, por \citeauthor{agrawal93mining}, a mineração de padrões freqüentes e regras de associação têm recebido grande atenção. Nas últimas décadas, centenas de artigos científicos foram publicados apresentando algoritmos, abordagens e melhorias para resolver problemas de mineração de padrões freqüentes e regras de associação de forma mais eficiente.
\par
Dentre as características mais importantes dos padrões freqüentes, podemos citar o suporte, que representa a medida de popularidade do padrão em relação à base. Um padrão é considerado freqüente se possui suporte maior que um dado limite inferior. Na prática, não estamos interessados apenas no conjunto de padrões freqüentes, mas também nos respectivos suportes destes padrões.

%Ótimo Survey sobre mineração de padrões freqüentes (possui descrição do problema, mineração de itemsets, espaço de busca, regras de associação, algoritmo apriori fp-growth, etc...): \cite{goethals03survey}.

\subsection{Regras de Associação}

Em mineração de dados, regras de associação são utilizadas para descobrir elementos que co-ocorrem freqüentemente numa determinada base de dados. A motivação por trás deste tema está relacionada com a grande quantidade de aplicações possíveis de se construir com o auxílio de regras de associação, como, por exemplo, questões relacionadas ao comportamento de clientes num determinado estabelecimento comercial.
\par
Considerando uma base de dados de transações em que cada transação represente uma ação de compra de determinado cliente, e cada item da transação represente um produto adquirido, regras de associação seriam uma boa opção para responder questões como:

\begin{itemize}
	\item Encontre todas as regras que possuem ``café'' como conseqüente. Estas regras poderiam auxiliar o usuário a planejar o que deve ser feito no estabelecimento para aumentar a venda daquele produto;
	\item Encontre todas as regras que possuem ``café'' como antecedente. Com estas regras seria possível descobrir que produtos serão impactados se o estabelecimento optar por descontinuar a venda daquele;
	\item Encontre todas as regras que possuem ``café'' como antecedente e ``leite'' como conseqüente. Esta requisição poderia ser realizada para todos os produtos do estabelecimento, com a intenção de se encontrar aqueles cujo consumo esteja relacionado;
	\item Encontre todas as regras relacionando itens localizados nas prateleiras A e B do estabelecimento. Estas regras poderiam auxiliar no planejamento das prateleiras, e na localização dos produtos;
	\item Encontre as $k$ ``melhores'' regras que possuem ``café'' como conseqüente. As ``melhores'' regras podem ser obtidas com o auxílio de métricas associadas a cada regra, como suporte e confiança.
\end{itemize}

Uma das características mais difundidas das regras de associação é a confiança. A confiança de uma regra representa a probabilidade de que uma transação da base de dados coberta pelo antecedente da regra também seja coberta pelo termo conseqüente. Em geral, além do conjunto de regras de associação, estamos interessados também no suporte dos termos antecedentes, e na confiança de cada regra.

%\par
%Artigo que fala de classificação e Regras de Associação: \cite{liu98integrating} (CBA)
%O Survey também fala de regras de associação: \cite{goethals03survey}.
%Artigo do Zaki, que fala também (CHARM): \cite{zaki99charm}.
%Novos algoritmos para descoberta rápida de regras de associação: \cite{DBLP:conf/kdd/ZakiPOL97}.

\section{Ortogonalidade}

Em matemática, ortogonalidade é, simplesmente, uma característica que denota perpendicularidade, ou existência de ângulos retos. Formalmente, dois vetores $x$ e $y$ são ortogonais num espaço vetorial $V$ se o produto interno $\left\langle x,y \right\rangle$ é zero. Esta situação é descrita por $x \bot y$.
\par
O termo pode ser estendido para o uso geral, denotando a característica de independência, não redundância, não sobreposição, e, até mesmo, irrelevância entre duas entidades. Neste trabalho, o termo ortogonalidade está mais relacionado com a ausência de redundância (ou sobreposição), ou seja, o inverso da similaridade.
\par
Os termos similaridade e ortogonalidade têm sido explorados em várias áreas da ciência da computação, e com diversos objetivos. Um exemplo é o caso do \textbf{Modelo de Espaço Vetorial}, aplicado à \textbf{Recuperação de Informação}, que utiliza modelos vetoriais e métricas de similaridade para se aproximar termos da pesquisa de um usuário aos documentos de determinada coleção.
\par
De acordo com \cite{salton75vsm}, o modelo de espaço vetorial, ou simplesmente modelo vetorial, representa documentos e consultas como vetores de termos. Aos termos das consultas e documentos são atribuídos pesos que especificam o tamanho e a direção do seu vetor de representação. Estes pesos são utilizados para calcular o grau de similaridade entre cada documento da coleção e a consulta de usuário. Dessa forma, o modelo vetorial leva em consideração documentos que casam com a consulta de forma parcial. Como resultado, o conjunto de respostas é ordenado de forma mais precisa que o antigo e limitado modelo booleano.
\par
Já a ortogonalidade, particularmente, tem sido explorada em áreas como visualização \citep{cui07}, reconhecimento facial \citep{nagao98}, taxonomia \citep{smith00}, dentre outras.
\par
Como exemplo de aplicação do termo em mineração de dados, podemos citar \cite{DBLP:conf/kdd/XinCYH06}, que utiliza métricas de significância e redundância para extrair, de um grande conjunto de padrões freqüentes, um sub-conjunto (top-$k$) de padrões com um valor mínimo de redundância. O autor comenta que este estudo abriu uma nova direção na procura por diferentes e significantes top-$k$ respostas para atividades de mineração de dados, que podem resultar em estudos promissores.

%\par
%Na próxima seção serão apresentados os objetivos deste trabalho, relacionados com os termos apresentados nesta introdução - mineração de dados, padrões freqüentes, regras de associação e ortogonalidade.

% como forma de se obter uma medida de dissimilaridade entre duas entidades quaisquer. Um exemplo é o caso do \textbf{Modelo de Espaço Vetorial}, aplicado à \textbf{Recuperação de Informação}.
%\par
%De acordo com \cite{salton75vsm}, o modelo de espaço vetorial, ou simplesmente modelo vetorial, representa documentos e consultas como vetores de termos. Termos são ocorrências únicas nos documentos. Os documentos devolvidos como resultado para uma consulta são representados similarmente, ou seja, o vetor resultado para uma consulta é montado através de um cálculo de similaridade. Aos termos das consultas e documentos são atribuídos pesos que especificam o tamanho e a direção de seu vetor de representação. Ao ângulo formado por estes vetores dá-se o nome de $q$. O termo $\cos(q)$ determina a proximidade da ocorrência. O cálculo da similaridade é baseado neste ângulo entre os vetores que representam o documento e a consulta.

%Boa fonte para ortogonalidade (termo geral) - wikepedia: http://en.wikipedia.org/wiki/Orthogonal \\
%Citar poucos artigos que tratam de ortogonalidade, como ORIGAMI \citep{zaki07origami}, Redundancy-Aware Top-k Patterns \citep{DBLP:conf/kdd/XinCYH06} e Orthogonal Decision Trees \citep{dutta2004orthogonal}. \\
%Procurar mais fontes.

\section{Objetivos}

Este trabalho visa explorar o problema de classificação associativa em mineração de dados considerando ortogonalidade entre padrões freqüentes com os seguintes objetivos:

\begin{itemize}
	\item Minimizar o número de padrões utilizados na geração das regras, extraindo, do conjunto de padrões freqüentes, um sub-conjunto de padrões ortogonais, para que, a partir destes, seja gerado o conjunto de regras associativas necessárias para se realizar a classificação;
	\item Diminuir a redundância das regras geradas, como conseqüência da utilização de ortogonalidade aplicada ao conjunto de padrões freqüentes;
	\item Diminuir a ambigüidade das regras geradas, como conseqüência da utilização de ortogonalidade aplicada à cobertura de classes e transações pelos padrões;
	\item Aumentar a efetividade das classificações, como conseqüência da diminuição da redundância e da ambigüidade das regras, de acordo com os itens acima.
\end{itemize}

\section{Trabalhos Relacionados}
\label{sec:introducao_trabalhos}

Na literatura, encontramos diversos trabalhos relacionados, tanto com classificação associativa quanto com a obtenção de top-$k$ padrões como forma de compactar o conjunto de padrões freqüentes obtidos de uma base de dados e simplificar a visualização dos resultados, sendo que alguns destes trabalhos também estão relacionados com o termo ortogonalidade.
\par
Em \cite{DBLP:conf/kdd/XinCYH06}, os autores introduzem o problema da extração dos top-$k$ padrões livres de redundância através de um modelo que integra duas métricas - significância e relevância - numa única função objetivo. A idéia é obter, a partir do conjunto de todos os padrões freqüentes obtidos por uma abordagem qualquer de mineração de dados, um conjunto de $k$ padrões de alta significância e baixa redundância entre seus elementos. Este conjunto deve ser obtido com o auxílio de uma função objetivo que relaciona as duas métricas propostas. O resultado é um conjunto de padrões não similares que representam bem todo o conjunto de padrões freqüentes. O artigo apresenta duas funções objetivo, e descreve um algoritmo guloso que resolve o problema com ordem de complexidade de tempo $O(\log k)$.
\par
Em \cite{Veloso06Lazy} é introduzida a abordagem \textit{lazy} de classificação associativa, apresentando as vantagens deste modelo quando comparado com a abordagem \textit{eager}, bastante explorada anteriormente em árvores de decisão e classificadores baseados em entropia. Em primeiro lugar, artigo demonstra que classificadores associativos \textit{eager} possuem desempenho melhor que árvores de decisão, e discute como regras de decisão podem ser geradas a partir de um modelo baseado em árvores de decisão. Em seguida, os autores apresentam a abordagem \textit{lazy}, e demonstram que ela produz resultados melhores que a abordagem \textit{eager}. Classificadores \textit{eager} geram regras antes que as instâncias de teste sejam analisadas. A dificuldade de se antecipar todas as direções possíveis da tarefa de classificação faz com que a abordagem produza regras muito generalizadas, o que pode reduzir a eficácia do classificador. A estratégia \textit{lazy}, no entanto, só produz regras aplicáveis à instância de teste, o que faz com que a eficácia do classificador não seja penalizado pela generalização. Os resultados apresentados compravam a superioridade da estratégia \textit{lazy}.
\par
Em \cite{veloso06multi}, os autores utilizam a abordagem \textit{lazy} de classificação associativa direcionado para classificação de documentos. O artigo apresenta um algoritmo de classificação capaz de analisar tanto o conteúdo dos documentos quanto a existências de \textit{links} de saída e de entrada para outros documentos. As inovações introduzidas pelos autores produzem resultados mais efetivos e de maior eficácia que abordagens do estado da arte nas coleções utilizadas.
\par
Em \cite{zaki07origami} encontramos um novo paradigma para obtenção de uma representação resumida do conjunto de padrões freqüentes. O artigo introduz uma metodologia randômica para obtenção de padrões maximais que possui, como principal característica, a possibilidade de cobrir uniformemente o espaço dos padrões, e ainda apresenta a formulação da obtenção do conjunto $\alpha$-ortogonal e $\beta$-representativo como um problema de otimização NP-Hard. Um conjunto de padrões é considerado $\alpha$-ortogonal se a similaridade entre os padrões que o compõem é menor ou igual a um determinado valor $\alpha$. Dado um conjunto de padrões, um sub-conjunto deste é $\beta$-representativo em relação aos elementos que não fazem parte dele se, para cada um destes elementos, existe um elemento no sub-conjunto cuja similaridade entre os dois é maior ou igual a $\beta$. O objetivo é obter sub-conjuntos de padrões não redundantes que possuem um certo nível de representatividade em relação ao conjunto original. Esta abordagem será discutida com mais detalhes na seção \ref{sec:ortogonalidade_origami}.
\par
O problema de compactação do conjunto de padrões freqüentes é explorado de diversas outras maneiras: \cite{TheobaldSW_BTW07} apresenta um \textit{framework} para indexação e recuperação em grandes coleções de dados estruturados, semi-estruturados e não estruturados. Em \cite{DBLP:conf/icde/ZhuYHYC07}, encontramos uma nova metodologia de mineração de padrões, que aproxima o conjunto resultado do conjunto de padrões freqüentes colossais. Em \cite{boulicaut03freesets} os autores introduzem uma estrutura chamada \textit{free-sets} de onde é possível aproximar o suporte de qualquer padrão da base. Os experimentos demonstram que a obtenção de \textit{free-sets} é possível mesmo quando a extração dos padrões freqüentes se torna intratável. Em \cite{fu00} encontramos uma nova forma de se obter o conjunto de padrões freqüentes sem a especificação de um suporte mínimo. Nesta abordagem, usuário deve simplesmente informar a quantidade de itens que deseja no conjunto-solução. Já em \cite{han02mining}, a abordagem de obtenção do conjunto-solução sem especificação de suporte é aplicada à mineração de padrões fechados. Neste caso, o usuário deve informar, além do tamanho desejável do conjunto-solução, o tamanho mínimo dos padrões, e, finalmente, \cite{xin05mining} apresenta o problema de compressão de padrões com o objetivo de encontrar um conjunto de padrões de tamanho mínimo que possua pelo menos um representante para cada padrão freqüente do conjunto real.
\par
Também encontramos muitos outros trabalhos relacionados com o problema da classificação: Em \cite{liu98integrating} é apresentada a proposta de integração entre as áreas mineração de regras de associação e classificação baseada em regras. \cite{zaki99charm} demonstra que é possível gerar regras de associação utilizando apenas padrões fechados, sem perda de informação, e apresenta um eficiente algoritmo para mineração destes padrões. Em \cite{DBLP:conf/sdm/WangK05} encontramos um algoritmo de geração de regras com o objetivo de incluir, no conjunto-resultado, apenas as regras de alta confiança encontradas para cada instância da base de teste. Em \cite{li01cmar} os autores apresentam um novo método de classificação associativa baseada em regras de múltipla associação. O algoritmo realiza a classificação de uma instância de teste com o auxílio de um sub-conjunto de regras que casam com a instância. Em \cite{DBLP:conf/sdm/YinH03}, encontramos um algoritmo guloso que gera as regras de associação diretamente da base de treinamento. \cite{kuok98mining} introduz regras de associação baseadas em \textit{fuzzy sets}. Em \cite{DBLP:conf/icde/ChengYHH07} os autores realizam um estudo do problema de classificação e apresentam um \textit{framework} que relaciona padrões freqüentes com métricas discriminativas tais como ganho de informação, e, finalmente, \cite{DBLP:conf/icde/LentSW97} apresenta um algoritmo de classificação \textit{multi-label} com a intenção de reduzir a redundância de informações durante o processo de aprendizado existente nas propostas anteriores.
\par
E ainda, a abordagem \textit{lazy} proposta por \cite{Veloso06Lazy}, e utilizada em \cite{veloso06multi}, também obteve resultados satisfatórios em outras aplicações: \citep{veloso06, Veloso2007}.

\section{Organização do Documento}

Este documento é dividido em cinco capítulos. O restante dos capítulos está organizado da seguinte forma:

\begin{itemize}
	\item O capítulo \ref{chapter:classificacao} possui uma base de informações relacionadas à classificação associativa, como definição do problema, definição e comparação entre as estratégias \textit{eager} e \textit{lazy}, e uma breve apresentação das métricas mais utilizadas para se comparar regras de associação;
	\item No capítulo \ref{chapter:ortogonalidade} será apresentada a nova estratégia de classificação baseada em ortogonalidade. O conteúdo inclui uma discussão sobre métricas e estratégias de ortogonalidade utilizadas, uma explicação detalhada da utilização de ortogonalidade pelo classificador e das heurística de obtenção de conjuntos ortogonais, e ainda a adaptação da estratégia ORIGAMI (mencionada na seção \ref{sec:introducao_trabalhos}) para o problema de classificação;
	\item No capítulo \ref{chapter:resultados} serão apresentados os experimentos executados e os resultados obtidos durante a realização do trabalho;
	\item O capítulo \ref{chapter:conclusao} possui um breve resumo do que foi apresentado, além de sugestões para futuros trabalhos relacionados ao tema.
\end{itemize}