%\chapter{Experimentos e Resultados}
\chapter{Experiments and Results}
\label{chapter:resultados}

%\section{O Aplicativo \textbf{OLAC}}
\section{The Applicative \textbf{OLAC}}

%\par
%Algumas informações sobre o aplicativo (linguagem, número de linhas, opções de execução (--help), %\par
%Mostrar gráfico de ortogonalidade? (métrica x acurácia)
%\par
%Mostrar tabela de acertos?
%\par
%O algoritmo não ortogonal está quase igual ao lazy - talvez ele nem precise ser citado
%\par

The applicative \textbf{OLAC} contains the implementation of an association-rule based classifier with three different approaches.
\par
The first one, called \textbf{LAC}, is the classical (and non-orthogonal) \textit{lazy} associative approach  as it was proposed in \cite{Veloso06Lazy}, that just obtains the frequent patterns set and generates rules with it. After that, it chooses the more indicated class according to the rules contained in a rank considering confidence, support and some other metrics.
\par
The second one, called \textbf{OLAC} is  the orthogonal \textit{lazy} associative aproach that obtains an orthogonal set of patterns from the frequent patterns, and generates rules from that pattern set. After that, it chooses the more indiated class the same way it is done with the non-orthogonal approach.
\par
The third one, called \textbf{ORIGAMI} is an implementation of ORIGAMI (as it was proposed in \cite{zaki07origami}) according to the addaptation show in section \ref{sec:ortogonalidade_origami_adaptacao}.
\par
The execution options are shown below:

\begin{verbatim}
Usage: ./olac [options]
Options:
  -i, --training-file       Set the training file
  -t, --testing-file        Set the testing file
  -s, --support             Set the support
  -c, --confidence          Set the confidence
  -r, --run-mode            Set the run mode [c,o] [CLASSICAL, ORTHOGONAL]
  -p, --pattern-set         Set the pattern set type [f,m,r] [FREQUENT,
                              MAXIMAL, RANDOM MAXIMAL]
  -n, --min-num-rules       Set the minimum number of rules
  -l, --max-num-rank-rules  Set the maximum number of rules considered in
                              rank (rank size)
  -m, --min-rule-len        Set the minimum length of the rules
  -x, --max-rule-len        Set the maximum length of the rules
  -o, --orth-mode           Set the orthogonality mode [h,p,o] [HEURISTICAL,
                              POLYNOMIAL, ORIGAMI]
  -e, --orth-metric         Set the orthogonality metric [s,c,l,a]
                              [SIMILARITY, TRANSACTION COVERAGE, CLASS
                              COVERAGE, ALL]
  -w, --orth-method         Set the way metrics are used [s,p,a] [SET, PAIR
                              AVERAGE, ALL]
  -g, --orth-pat-ordering   Set the way patterns are ordered for heuristic
                              [s,r,i,z,n] [SORTED, REVERSE SORTED, SORTED BY
                              SIZE, REVERSE SORTED BY SIZE, NONE]
  -a, --origami-alpha       Set the alpha parameter used by ORIGAMI
  -b, --origami-beta        Set the beta parameter used by ORIGAMI
  -d, --debug               Set the level of debug [0-4] [NODEBUG - MAXLEVEL]
  -v, --verbose             Use verbose mode
  -h, --help                Display this information
\end{verbatim}

The options \textbf{-i} and \textbf{-t} are used to give training and testing files. Support for frquent patter mining and confidence for association rule generation are given by \textbf{s} and \textbf{c}. The option \textbf{-r} is used to choose the running mode (classical, for LAC and orthogonal for OLAC and ORIGAMI). Option \textbf{-p} is used to choose the set of patterns that should be mined by the application. Basically, frequent patterns are used by LAC and OLAC versions, and random maximal frequent patterns are used by ORIGAMI, but it is possible to run \textbf{olac} with different combinations of approaches and pattern sets. The \textbf{-n} options is used to give the minimum number of rules. If it is not possible to generate a minimum number of rules according to the confidence parameter, \textbf{olac} tries to generate rules with lower confidences until this threshold is reached. The \textbf{-l} parameter is used to give the maximum ranking size. The options \textbf{-m} and \textbf{-x} are used to set minimum and maximum number of items in the left side of the rules. The orthogonality mode is given by \textbf{-o}. The used may choose the heuristical mode (OLAC), the polynomial mode (a very expensive approach, that tries all combinations for each set explored), and the ORIGAMI mode. The option \textbf{-e} is used to set the orthogonality metric used by orthogonal modes. The options \textbf{-w} and \textbf{-g} are used to give the way metrics are used and the way patterns are ordered for heauristical mode. The options \textbf{-a} and \textbf{-b} are $\alpha$ and $\beta$, parameters for ORIGAMI approach.

\section{Execution Example}

An example to demonstrate the OLAC execution:

The training data set of table \ref{tab:example_training_db} was created over the set of items $\I = \left\{ A, B, C, D, E \right\}$

\input{tables/table_example_training_db.tex}

And a testing data set with the transaction $ABE$ and class $CLASS=1$ was used in the test. The applicative \textbf{olac} was first executed with \textbf{LAC} (or non-orthogonal) mode using the parameters found in table \ref{tab:example_run_parms}.

\input{tables/table_example_run_parms.tex}

\clearpage

%não-ortogonal: 
%accuracy [1], average patterns [7], average rules [15], average time [0.000428]
%padrões:
%A
%B
%E
%A B
%A E
%B E
%A B E
This execution generated the frequent pattern set $\F = \left\{ A, B, E, AB, AE, BE, ABE \right\}$ and classified correctly the instance. After that, the applicative was executed in \textbf{OLAC} (or orthogonal) mode using the same parameters found in table \ref{tab:example_run_parms}, and similarity as the orthogonality metric. This approach extracted the orthogonal pattern set $\Or = \left\{ AE, B \right\}$ from the frequent pattern set and still classified correctly the instance. As we can see, the set of patterns used by orthogonal mode is much smaller than the original set of frequent patterns. And more, the orthogonal set doesn't have redundancy. It is expected that the redundancy of orthogonal pattern sets are lower than the redundancy of original frequent pattern sets.
\par
%ortogonal - similarity (reverse sorted by side):
%accuracy [1], average patterns [2], average rules [4], average time [0.001799]
%padrões:
%A E
%B
%
%ortogonal - coverage (sorted):
%accuracy [1], average patterns [2], average rules [5], average time [0.003535]
%padrões:
%A B
%E
%
%ortogonal - class coverage (sorted by side):
%accuracy [1], average patterns [2], average rules [5], average time [0.003621]
%padrões:
%B
%E
The applicative was executed with transaction coverage and class coverage as the orthogonality metrics too, extracting, respectively, $\Or = \left\{ AB, E \right\}$ and $\Or = \left\{ B, E \right\}$ as orthogonal pattern sets, and these executions classified the instance correctly too.

\section{Experiments}

Now, we will show some graphics comparing the executions of the three approaches implemented: LAC, OLAC and ORIGAMI. %, but first we will do some observations about these test instances:
%\par
%\begin{itemize}
%	\item LAC was run with support 1, just because this is the objective of LAC (the Adriano Veloso implementation) - to get better results with the minimum support value;
%	\item ORIGAMI was run with $\alpha = 0.2$, and $\beta = 0.8$, we need to make more tests with another values for $\alpha$ and $\beta$ in order to get better results;
%	\item We are still running these experiments with anoter parameters, and trying to get some better results for all approaches.
%\end{itemize}
\par
The figure \ref{fig:histogram_best_run_for_each_db_acc} shows a histogram with the best accuracies for each dataset obtained with the three approaches. The figure \ref{fig:histogram_best_run_for_each_db_pat} shows a histogram with the average number of patterns used for each classification, the figure \ref{fig:histogram_best_run_for_each_db_rul} shows the average number of rules generated for each classification, and the figure \ref{fig:histogram_best_run_for_each_db_tim} shows the average time spent for each classification. For these four results it was used the best sets of parameters for each application and dataset, for example, considering the orthogonal classifier OLAC, for anneal.ac we used support equals to 0.001, but for waveform.ac we used support equals to 0.0001, since the best results were obtained with this value.

\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.95\textwidth]{graphs/histogram_best_run_for_each_db_acc}
	\caption{Accuracy Histogram (best results for each dataset)}
	\label{fig:histogram_best_run_for_each_db_acc}
\end{figure}

As we can see in the figure \ref{fig:histogram_best_run_for_each_db_acc}, the accuracies for orthogonal and non-orthogonal versions of our classifier are very close. the average accuracy obtained for them were $0.8085$ and $0.8088$ respectively, and they are both better than LAC.

\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.95\textwidth]{graphs/histogram_best_run_for_each_db_pat}
	\caption{Patterns Histogram (best results for each dataset)}
	\label{fig:histogram_best_run_for_each_db_pat}
\end{figure}

The number of patterns generated by orthogonal version of our classifier (shown by figure \ref{fig:histogram_best_run_for_each_db_pat}) is lower than the LAC ones. The difference would be still greater (as it was comparing our orthogonal and non-orthogonal versions) if we used lower values for confidence in LAC (the value for this parameter that produced better results in average was $0.95$.

\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.95\textwidth]{graphs/histogram_best_run_for_each_db_rul}
	\caption{Rules Histogram (best results for each dataset)}
	\label{fig:histogram_best_run_for_each_db_rul}
\end{figure}

The number of patterns generated by orthogonal version of our classifier (shown by figure \ref{fig:histogram_best_run_for_each_db_rul}) is higher than the LAC ones. This happened because the same - the values for confidence used for LAC were very high. We believe that if we run LAC with lower values for confidence, this number will be much higher.

\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.95\textwidth]{graphs/histogram_best_run_for_each_db_tim}
	\caption{Classification Time Histogram (best results for each dataset)}
	\label{fig:histogram_best_run_for_each_db_tim}
\end{figure}

\clearpage

The table \ref{tab:best_runs_for_each_db_lac} shows the parameters used LAC and the best results for each dataset.

\input{tables/table_best_runs_lac.tex}

\clearpage

The table \ref{tab:best_runs_for_each_db_olac} shows the parameters used OLAC and the best results for each dataset.

\input{tables/table_best_runs_olac.tex}

\clearpage

The table \ref{tab:best_runs_for_each_db_origami} shows the parameters used ORIGAMI and the best results for each dataset.

\input{tables/table_best_runs_origami.tex}

\clearpage

The figure \ref{fig:histogram_best_run_for_avg_db_acc} shows a histogram with the best accuracies for each dataset obtained with LAC, ORIGAMI, orthogonal classifier and non-orthogonal classifier. The figure \ref{fig:histogram_best_run_for_avg_db_pat} shows a histogram with the average number of patterns used for each classification, the figure \ref{fig:histogram_best_run_for_avg_db_rul} shows the average number of rules generated for each classification and the figure \ref{fig:histogram_best_run_for_avg_db_tim} shows the average spent for each classification. For those three results it was used, for each application, the set of parameters that produced the best average accuracy for the whole set of data. The values for each parameter are shown in table \ref{tab:best_parms_for_avg_db}. Some parameters are not applicable to all approaches.

\input{tables/table_best_parms_for_avg_db.tex}

\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.95\textwidth]{graphs/histogram_best_run_for_avg_db_acc}
	\caption{Accuracy Histogram (best average results for all datasets)}
	\label{fig:histogram_best_run_for_avg_db_acc}
\end{figure}

\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.95\textwidth]{graphs/histogram_best_run_for_avg_db_pat}
	\caption{Patterns Histogram (best average results for all datasets)}
	\label{fig:histogram_best_run_for_avg_db_pat}
\end{figure}

The number of patterns generated with ORIGAMI approach in figure \ref{fig:histogram_best_run_for_avg_db_pat} was $1$ (one) for all datasets. This happened because the best combined values for support and confidence found was $0.001$ and $0.1$, and this, possibly, didn't generate any valid rule, since the low support generates big maximal patterns, and $0.1$ is a sufficient value for confidence to turn all rules invalid. Since the applicative tries to generate, at least, one rule for each test instance, just one of the rules is added to the result. As it was told before, we are running the experiment with more parameter combinations, searching for better results.

\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.95\textwidth]{graphs/histogram_best_run_for_avg_db_rul}
	\caption{Rules Histogram (best average results for all datasets)}
	\label{fig:histogram_best_run_for_avg_db_rul}
\end{figure}

\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.95\textwidth]{graphs/histogram_best_run_for_avg_db_tim}
	\caption{Classification Time Histogram (best average results for all datasets)}
	\label{fig:histogram_best_run_for_avg_db_tim}
\end{figure}

\clearpage

In table \ref{tab:comparison_lac_olac} we have a comparison between the execution of LAC and OLAC approaches. This table shows the number of hits of both (second column), the number of hits of OLAC that LAC didn't get (third column), the number of hits of LAC that OLAC didn't get (fourth column) and the number of instances that both missed.

\input{tables/table_comparison_lac_olac.tex}

\clearpage

In table \ref{tab:comparison_lac_origami} we have a comparison between the execution of LAC and ORIGAMI approaches. This table shows the number of hits of both (second column), the number of hits of ORIGAMI that LAC didn't get (third column), the number of hits of LAC that ORIGAMI didn't get (fourth column) and the number of instances that both missed.

\input{tables/table_comparison_lac_origami.tex}

\clearpage

In table \ref{tab:comparison_olac_origami} we have a comparison between the execution of OLAC and ORIGAMI approaches. This table shows the number of hits of both (second column), the number of hits of OLAC that ORIGAMI didn't get (third column), the number of hits of ORIGAMI that OLAC didn't get (fourth column) and the number of instances that 
both missed.

\input{tables/table_comparison_olac_origami.tex}

%\section{Comparação Ortogonal x Não Ortogonal}
%
%Histogramas de acurácia, número de padrões e número de regras. \\
%Comparar melhor conjunto de parâmetros para cada arquivo e melhor conjunto de parâmetros para todos os arquivos juntos.
%
%\section{Comparação Ortogonal x LAC}
%
%Histogramas de acurácia, número de padrões e número de regras. \\
%Comparar melhor conjunto de parâmetros para cada arquivo e melhor conjunto de parâmetros para todos os arquivos juntos.
%
%\section{Comparação Ortogonal x ORIGAMI}
%
%Histogramas de acurácia, número de padrões e número de regras. \\
%Comparar melhor conjunto de parâmetros para cada arquivo e melhor conjunto de parâmetros para todos os arquivos juntos.
